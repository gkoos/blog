<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Backpressure in JavaScript: The Hidden Force Behind Streams, Fetch, and Async Code</title>
  <meta name="description" content="Master backpressure in JavaScript: how streams, fetch, and async code control data flow. Prevent memory spikes, latency collapse, and crashes in Node.js and the browser.">

  <!-- Facebook Meta Tags -->
  <meta property="og:url" content="https://gaborkoos.com">
  <meta property="og:type" content="website">
  <meta property="og:title" content="Backpressure in JavaScript: The Hidden Force Behind Streams, Fetch, and Async Code">
  <meta property="og:description" content="Master backpressure in JavaScript: how streams, fetch, and async code control data flow. Prevent memory spikes, latency collapse, and crashes in Node.js and the browser.">
  <meta property="og:image" content="https://opengraph.b-cdn.net/production/images/74740c4e-d40d-49be-83fb-7170084dbda1.png?token=3Pxj4Ccc7Z93zXgN6-HhJM8U3lpcnqtTs8xNIPoUzF4&height=614&width=620&expires=33290472379">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta property="twitter:domain" content="gaborkoos.com">
  <meta property="twitter:url" content="https://gaborkoos.com">
  <meta name="twitter:title" content="Backpressure in JavaScript: The Hidden Force Behind Streams, Fetch, and Async Code">
  <meta name="twitter:description" content="Master backpressure in JavaScript: how streams, fetch, and async code control data flow. Prevent memory spikes, latency collapse, and crashes in Node.js and the browser.">
  <meta name="twitter:image" content="https://opengraph.b-cdn.net/production/images/74740c4e-d40d-49be-83fb-7170084dbda1.png?token=3Pxj4Ccc7Z93zXgN6-HhJM8U3lpcnqtTs8xNIPoUzF4&height=614&width=620&expires=33290472379">

  <!-- Meta Tags Generated via https://www.opengraph.xyz -->

  <!-- Analytics -->
  <script data-goatcounter="https://gkoos.goatcounter.com/count"  async src="//gc.zgo.at/count.js"></script>

  
  
  


  <link rel="icon" type="image/x-icon" href="/assets/images/favicon.ico" />
  <link rel="stylesheet" href="/assets/css/styles.css" />
  <link rel="stylesheet" href="/assets/css/vendor/prism-tomorrow.css" />
  <link rel="stylesheet" href="/assets/css/fix-inline-code.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body class="bg-white dark:bg-gray-900 text-gray-900 dark:text-gray-100 font-['Inter',system-ui,sans-serif] antialiased leading-relaxed">
  <!-- Header/Navigation with Theme Switcher -->
  <header class="border-b border-gray-100 bg-white dark:bg-gray-900 text-gray-900 dark:text-gray-100 sticky top-0 z-10 transition-colors">
    <div class="max-w-4xl mx-auto px-6 py-6">
      <nav class="flex items-center justify-between">
        <div>
          <a href="/" class="text-base sm:text-xl font-semibold text-gray-900 dark:text-white hover:text-gray-700 dark:hover:text-gray-300 transition-colors mr-4 sm:mr-0">
            a developer blog
          </a>
        </div>
        <div class="flex items-center space-x-6">
          <a href="/" class="text-sm text-gray-600 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white transition-colors">Home</a>
          <a href="https://gaborkoos.com" class="text-sm text-gray-600 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white transition-colors">About</a>
          <a href="/publications" class="text-sm text-gray-600 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white transition-colors">Publications</a>
          <a href="/categories" class="text-sm text-gray-600 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white transition-colors">Categories</a>
          <a href="/feed.xml" class="text-sm text-gray-600 dark:text-gray-300 hover:text-gray-900 dark:hover:text-white transition-colors">RSS</a>
          <!-- Theme Switcher Button -->
          <button id="theme-toggle" aria-label="Toggle dark mode" class="ml-4 p-2 rounded focus:outline-none bg-white dark:bg-gray-900 text-gray-700 dark:text-gray-200 transition-colors" style="display:inline-block;">
            <span id="theme-toggle-light" style="display:none">ðŸŒž</span>
            <span id="theme-toggle-dark" style="display:none">ðŸŒ™</span>
          </button>
        </div>
      </nav>
    </div>
  </header>


  <main class="max-w-4xl mx-auto px-6 py-12 transition-colors">
  <div class="prose prose-lg prose-gray dark:prose-invert max-w-none">
    
<article>
  <h1 class="text-3xl font-bold mb-4">Backpressure in JavaScript: The Hidden Force Behind Streams, Fetch, and Async Code</h1>
  <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
    <time datetime="2026-01-06T00:00:00.000Z">Tue Jan 06 2026</time>
    
    
      <span class="text-gray-300">â€¢</span>
      <div class="flex flex-wrap gap-2">
        
          <div class="flex items-center rounded-full bg-teal-500 text-white dark:bg-teal-400/10 dark:text-teal-300 px-3 py-1 text-xs font-medium leading-5">javascript</div>
        
          <div class="flex items-center rounded-full bg-teal-500 text-white dark:bg-teal-400/10 dark:text-teal-300 px-3 py-1 text-xs font-medium leading-5">typescript</div>
        
      </div>
    
  </div>
  <div class="prose dark:prose-invert max-w-none">
    <p>We all know JavaScript's asynchronous model. <code>async/await</code>, <code>Promises</code>, and streams give the illusion that code runs sequentially while magically handling heavy work in the background. But if you've ever processed a large file, streamed data from an API, or handled bursts of network requests, you've probably run into a familiar problem: memory usage spikes, CPU sits idle, or your server crashes under a sudden load. &quot;Everything is async&quot;, so what is going on?</p>
<p>The answer lies in a concept many developers have never heard by name: <em>backpressure</em>. Backpressure is the system-level feedback mechanism that allows a consumer to slow down a producer when it's producing data faster than the consumer can handle. Without it, your asynchronous tasks wouldn't just run concurrently, they'd pile up, creating unbounded queues in memory and ultimately breaking your application.</p>
<p>In JavaScript, backpressure exists in multiple places: Node.js streams, the Fetch API, Web Streams, and even async loops over large datasets. But it can be tricky. The language gives you the tools: <code>ReadableStream</code>, <code>WritableStream</code>, stream events like <code>drain</code> - but it doesn't enforce correct usage. And many developers end up ignoring these signals, mostly because the code &quot;just works&quot; on small datasets. Then the data grows, the load increases, and suddenly your app is struggling to keep up: crashes, OOMs, and latency spikes seem to come out of nowhere.</p>
<p>This article will unpack what backpressure really is, why it matters in JavaScript, and how to write async code that respects it. By the end, you'll see that backpressure isn't a limitation, it's a feature of well-behaved systems, and understanding it can save you from countless production headaches.</p>
<h2 id="what-backpressure-actually-is-(and-isn't)" tabindex="-1"><a class="header-anchor" href="#what-backpressure-actually-is-(and-isn't)">What Backpressure Actually Is (and Isn't)</a></h2>
<p>Backpressure is one of those concepts that feels obvious once you see it, but most developers only realize it happening when their app starts breaking under load. Letâ€™s unpack it carefully.</p>
<h3 id="producer-vs-consumer" tabindex="-1"><a class="header-anchor" href="#producer-vs-consumer">Producer vs Consumer</a></h3>
<p>At its core, backpressure is about <strong>communication between a producer and a consumer</strong>:</p>
<ul>
<li><strong>Producer</strong>: anything that generates data. Examples in JavaScript include a network request, a file reader, or an async generator.</li>
<li><strong>Consumer</strong>: anything that processes data. This could be parsing JSON, writing to disk, or sending data over a WebSocket.</li>
</ul>
<p>Problems arise when the producer generates data faster than the consumer can handle. Without a way to slow down the producer, data starts piling up in memory, creating unbounded queues that eventually crash your app. For example:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">async</span> <span class="token keyword">function</span> <span class="token function">processData</span><span class="token punctuation">(</span><span class="token parameter">generator</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">for</span> <span class="token keyword">await</span> <span class="token punctuation">(</span><span class="token keyword">const</span> chunk <span class="token keyword">of</span> <span class="token function">generator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token function">heavyProcessing</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span> <span class="token comment">// slow consumer</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Even though <code>for await</code> looks sequential, the <code>generator</code> might produce chunks faster than <code>heavyProcessing</code> can handle, resulting in memory bloat, asynchronous CPU spikes, and eventual crashes.</p>
<h3 id="what-backpressure-means" tabindex="-1"><a class="header-anchor" href="#what-backpressure-means">What Backpressure Means</a></h3>
<p>Backpressure is the <strong>mechanism that lets the consumer signal the producer to slow down</strong>. In JavaScript, this often happens implicitly in streams:</p>
<ul>
<li>When <code>writable.write(chunk)</code> returns false, it tells the producer to stop writing temporarily.</li>
<li>When using <code>readable.pipe(writable)</code>, the pipe manages flow automatically.</li>
<li>In web streams, the <code>pull()</code> method only asks for more data when the consumer is ready.</li>
</ul>
<p>Key point: backpressure is about <strong>rate control</strong>, not order of execution or batching. Simply buffering all incoming data is not backpressure, it just postpones the problem!</p>
<h3 id="how-ignoring-it-breaks-things" tabindex="-1"><a class="header-anchor" href="#how-ignoring-it-breaks-things">How Ignoring It Breaks Things</a></h3>
<p>Ignoring backpressure can lead to a few familiar symptoms:</p>
<ul>
<li><strong>Memory spikes</strong>: Data piles up in memory faster than it can be processed.</li>
<li><strong>Latency collapse</strong>: Requests slow down unpredictably as queues grow.</li>
<li><strong>Crashes / OOMs</strong>: Eventually, the process runs out of memory.</li>
</ul>
<p>Buffers and queues can hide the problem temporarily, but they don't solve it. True backpressure is about coordination, ensuring that the producer never overwhelms the consumer.</p>
<p>In the next section, we'll briefly look at how backpressure appears outside JavaScript, and why it's a problem every system-level programmer has had to solve, even before JS existed.</p>
<h2 id="backpressure-before-javascript" tabindex="-1"><a class="header-anchor" href="#backpressure-before-javascript">Backpressure Before JavaScript</a></h2>
<p>Backpressure didn't start with JavaScript. It's a fundamental concept in computing systems: something developers have been dealing with long before <code>ReadableStream</code> or Node.js existed. Understanding its history helps explain why it exists in JS today and why it matters.</p>
<h3 id="pipes-and-streams-in-unix" tabindex="-1"><a class="header-anchor" href="#pipes-and-streams-in-unix">Pipes and Streams in Unix</a></h3>
<p>In Unix, the classic example is a pipeline of processes:</p>
<pre class="language-bash"><code class="language-bash"><span class="token function">cat</span> largefile.txt <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"error"</span> <span class="token operator">|</span> <span class="token function">sort</span> <span class="token operator">|</span> <span class="token function">uniq</span>
</code></pre>
<p>Each process is a consumer of the previous process's output and a producer for the next. If one process reads slower than its predecessor writes, Unix automatically pauses the faster process until the slower one catches up. That's backpressure in action: a natural flow-control mechanism built into the system.</p>
<h3 id="tcp-flow-control" tabindex="-1"><a class="header-anchor" href="#tcp-flow-control">TCP Flow Control</a></h3>
<p>At the network level, TCP also relies on backpressure. If a receiver cannot process incoming packets fast enough, it tells the sender to slow down via windowing and acknowledgment mechanisms. Without this feedback, network buffers could overflow, leading to dropped packets and retransmissions.</p>
<h3 id="messaging-systems" tabindex="-1"><a class="header-anchor" href="#messaging-systems">Messaging Systems</a></h3>
<p>Message queues, like RabbitMQ or Kafka, implement backpressure as well. Producers either block or receive signals when queues are full, ensuring consumers aren't overwhelmed. Systems that ignore this risk data loss or memory exhaustion.</p>
<h3 id="why-it-matters-for-js-developers" tabindex="-1"><a class="header-anchor" href="#why-it-matters-for-js-developers">Why It Matters for JS Developers</a></h3>
<p>These examples show that backpressure is a property of any system where <strong>work is produced faster than it can be consumed</strong>. JavaScript inherits the same problem in streams, async iterators, fetch, and beyond. What's different in JS is the language gives you the primitives, but not the enforcement: if you ignore the signals, your memory grows and your app breaks.</p>
<h2 id="backpressure-in-node.js-streams" tabindex="-1"><a class="header-anchor" href="#backpressure-in-node.js-streams">Backpressure in Node.js Streams</a></h2>
<p>Node.js popularized backpressure through its <code>streams API</code>, which provides a robust mechanism for controlling data flow between producers and consumers. Understanding streams is essential for writing high-performance, memory-safe Node applications.</p>
<h3 id="readable-streams-and-highwatermark" tabindex="-1"><a class="header-anchor" href="#readable-streams-and-highwatermark">Readable Streams and <code>highWaterMark</code></a></h3>
<p>A <em>Readable Stream</em> is a source of data: like a file, HTTP request, or socket. Internally, Node buffers data in memory. The key parameter controlling backpressure is <code>highWaterMark</code>, which sets the soft limit of the internal buffer:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">const</span> fs <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'fs'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> stream <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">createReadStream</span><span class="token punctuation">(</span><span class="token string">'largefile.txt'</span><span class="token punctuation">,</span> <span class="token punctuation">{</span> <span class="token literal-property property">highWaterMark</span><span class="token operator">:</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Here, <code>highWaterMark</code> is 16 KB. When the buffer reaches this limit, the stream stops reading from the underlying source until the buffer is drained. This is the first layer of backpressure: the producer slows down when the consumer cannot keep up.</p>
<h3 id="writable-streams-and-the-write()-return-value" tabindex="-1"><a class="header-anchor" href="#writable-streams-and-the-write()-return-value">Writable Streams and the <code>write()</code> Return Value</a></h3>
<p>A <em>Writable Stream</em> consumes data. The most common mistake is ignoring the return value of <code>write()</code>. This boolean tells you whether the internal buffer is full:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">const</span> fs <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'fs'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> writable <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">createWriteStream</span><span class="token punctuation">(</span><span class="token string">'output.txt'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">function</span> <span class="token function">writeData</span><span class="token punctuation">(</span><span class="token parameter">data</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>writable<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// backpressure signal: wait for 'drain'</span>
    writable<span class="token punctuation">.</span><span class="token function">once</span><span class="token punctuation">(</span><span class="token string">'drain'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">{</span>
      console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token string">'Buffer drained, continue writing'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>If you ignore <code>false</code> and keep writing, Node will buffer everything in memory, eventually causing your app to run out of memory. The <code>drain</code> event signals that it's safe to resume writing.</p>
<h3 id="using-pipe()-for-automatic-backpressure" tabindex="-1"><a class="header-anchor" href="#using-pipe()-for-automatic-backpressure">Using <code>pipe()</code> for Automatic Backpressure</a></h3>
<p>Node streams also support automatic backpressure management through <code>pipe()</code>. When you <em>pipe</em> a readable to a writable, Node internally listens for the consumer's signals and pauses/resumes the producer accordingly:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">const</span> fs <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'fs'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">const</span> readable <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">createReadStream</span><span class="token punctuation">(</span><span class="token string">'largefile.txt'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> writable <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">createWriteStream</span><span class="token punctuation">(</span><span class="token string">'copy.txt'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

readable<span class="token punctuation">.</span><span class="token function">pipe</span><span class="token punctuation">(</span>writable<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Here, the readable stream automatically pauses when the <code>writable</code>'s buffer is full and resumes when the <code>drain</code> event fires. This makes <code>pipe()</code> one of the simplest and safest ways to handle backpressure.</p>
<h3 id="common-pitfalls" tabindex="-1"><a class="header-anchor" href="#common-pitfalls">Common Pitfalls</a></h3>
<p>Even with streams, it's easy to break backpressure:</p>
<ul>
<li>Ignoring <code>write()</code> return values: queues grow unchecked.</li>
<li>Using <code>Promise.all()</code> on chunks: creates unbounded concurrency. Many writes may happen simultaneously, overwhelming the writable stream.</li>
<li>Reading everything into memory: <code>readFileSync</code> or <code>fs.promises.readFile</code> may crash on large files.</li>
</ul>
<p>Streams exist because they provide flow control by design. Learning to respect the signals (<code>write()</code> return value, <code>drain</code>, <code>pipe()</code>) is how you implement real backpressure in Node.js.</p>
<p>Node streams expose a built-in contract between producer and consumer. If you ignore it, your memory grows - if you respect it, your application handles large or fast data sources safely.</p>
<h2 id="how-async%2Fawait-can-accidentally-destroy-backpressure" tabindex="-1"><a class="header-anchor" href="#how-async%2Fawait-can-accidentally-destroy-backpressure">How <code>async/await</code> Can Accidentally Destroy Backpressure</a></h2>
<p><code>async/await</code> is one of JavaScript's greatest abstractions for writing readable asynchronous code. But it can also mask backpressure problems, making you think your consumer is keeping up when it isn't. Understanding this is crucial for building reliable, memory-safe applications.</p>
<h3 id="the-illusion-of-sequential-safety" tabindex="-1"><a class="header-anchor" href="#the-illusion-of-sequential-safety">The Illusion of Sequential Safety</a></h3>
<p>It's easy to assume that wrapping work in await naturally enforces proper flow control:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">for</span> <span class="token keyword">await</span> <span class="token punctuation">(</span><span class="token keyword">const</span> chunk <span class="token keyword">of</span> stream<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token function">process</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// heavy CPU work</span>
<span class="token punctuation">}</span>
</code></pre>
<p>At first glance, this seems safe: each chunk is processed before moving to the next. But if <code>process(chunk)</code> launches asynchronous tasks internally - like database writes or network requests - the actual concurrency may be much higher than it appears. The producer continues to deliver new chunks to your loop while earlier tasks are still pending, causing memory growth.</p>
<h3 id="the-promise.all()-trap" tabindex="-1"><a class="header-anchor" href="#the-promise.all()-trap">The <code>Promise.all()</code> Trap</a></h3>
<p>A common pattern is to process multiple chunks concurrently using Promise.all():</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">const</span> chunks <span class="token operator">=</span> <span class="token keyword">await</span> <span class="token function">getAllChunks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">await</span> Promise<span class="token punctuation">.</span><span class="token function">all</span><span class="token punctuation">(</span>chunks<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>processChunk<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>This eagerly starts all chunk processing in parallel. For small datasets, this works fine, but with large streams, you're effectively <strong>removing any backpressure, because the producer's work is no longer paced by the consumer</strong>! Memory usage spikes, and your process may crash.</p>
<h3 id="why-await-%E2%89%A0-flow-control" tabindex="-1"><a class="header-anchor" href="#why-await-%E2%89%A0-flow-control">Why Await â‰  Flow Control</a></h3>
<p>Even <code>for await</code> loops don't inherently enforce backpressure if the work inside the loop is asynchronous:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">for</span> <span class="token keyword">await</span> <span class="token punctuation">(</span><span class="token keyword">const</span> chunk <span class="token keyword">of</span> readableStream<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token function">someAsyncTask</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// fire-and-forget</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Here, the loop awaits only the next chunk, not the completion of someAsyncTask. The readable stream continues producing new chunks, and your memory usage grows unbounded.</p>
<p>Rule of thumb: <strong>backpressure requires the consumer to signal readiness</strong>. Just awaiting the next item in a loop does not automatically create that signal if your processing is asynchronous.</p>
<h3 id="patterns-that-preserve-backpressure" tabindex="-1"><a class="header-anchor" href="#patterns-that-preserve-backpressure">Patterns That Preserve Backpressure</a></h3>
<p>To maintain backpressure with <code>async/await</code>, consider:</p>
<ul>
<li><strong>Sequential processing</strong>: await each async task before moving to the next.</li>
<li><strong>Bounded concurrency</strong>: limit the number of in-flight promises with a small worker pool.</li>
<li><strong>Respect stream signals</strong>: combine await with the <code>writable</code>'s <code>write()</code> return value or <code>drain</code> event.</li>
</ul>
<p>Example using bounded concurrency:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">import</span> pMap <span class="token keyword">from</span> <span class="token string">'p-map'</span><span class="token punctuation">;</span>

<span class="token keyword">const</span> <span class="token function-variable function">mapper</span> <span class="token operator">=</span> <span class="token keyword">async</span> <span class="token punctuation">(</span><span class="token parameter">chunk</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token keyword">await</span> <span class="token function">processChunk</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">await</span> <span class="token function">pMap</span><span class="token punctuation">(</span>readableStream<span class="token punctuation">,</span> mapper<span class="token punctuation">,</span> <span class="token punctuation">{</span> <span class="token literal-property property">concurrency</span><span class="token operator">:</span> <span class="token number">5</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Here, <code>p-map</code> ensures at most 5 chunks are processed concurrently, preventing runaway memory growth while still allowing parallelism.</p>
<p>Remember, <code>async/await</code> is syntactic sugar, not a flow-control mechanism. If your asynchronous work inside a loop or <code>Promise.all()</code> is unbounded, you break backpressure and risk crashes or latency spikes.</p>
<h2 id="backpressure-in-fetch%2C-web-streams%2C-and-the-browser" tabindex="-1"><a class="header-anchor" href="#backpressure-in-fetch%2C-web-streams%2C-and-the-browser">Backpressure in Fetch, Web Streams, and the Browser</a></h2>
<p>Backpressure of course isn't limited to Node.js. In the browser, modern APIs like <code>fetch</code> and <code>Web Streams</code> expose similar flow-control mechanisms, though they can be even subtler because of the single-threaded UI environment.</p>
<h3 id="fetch-%2B-streams" tabindex="-1"><a class="header-anchor" href="#fetch-%2B-streams">Fetch + Streams</a></h3>
<p>When you call fetch, the response body can be accessed as a stream:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">const</span> response <span class="token operator">=</span> <span class="token keyword">await</span> <span class="token function">fetch</span><span class="token punctuation">(</span><span class="token string">'/large-file'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> reader <span class="token operator">=</span> response<span class="token punctuation">.</span>body<span class="token punctuation">.</span><span class="token function">getReader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">const</span> <span class="token punctuation">{</span> value<span class="token punctuation">,</span> done <span class="token punctuation">}</span> <span class="token operator">=</span> <span class="token keyword">await</span> reader<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>done<span class="token punctuation">)</span> <span class="token keyword">break</span><span class="token punctuation">;</span>
  <span class="token function">processChunk</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Here, the <code>read()</code> call implicitly applies backpressure. <strong>The browser will not deliver the next chunk until the previous one has been consumed</strong>. If your <code>processChunk</code> function is slow or CPU-intensive, the stream naturally slows down the network reading, preventing memory overload.</p>
<p>However, if you accidentally read the entire response at once using <code>response.text()</code> or <code>response.arrayBuffer()</code>, you bypass backpressure entirely, <strong>forcing the browser to allocate memory for the whole payload at once</strong>.</p>
<h3 id="web-streams-api" tabindex="-1"><a class="header-anchor" href="#web-streams-api">Web Streams API</a></h3>
<p>The Web Streams API generalizes this pattern. Streams in the browser support two key mechanisms for backpressure:</p>
<h4 id="pull-based-reading" tabindex="-1"><a class="header-anchor" href="#pull-based-reading">Pull-based reading</a></h4>
<p>Consumers request more data when ready using a <code>pull()</code> method in a custom <code>ReadableStream</code>:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">const</span> stream <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ReadableStream</span><span class="token punctuation">(</span><span class="token punctuation">{</span>
  <span class="token function">start</span><span class="token punctuation">(</span><span class="token parameter">controller</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">/* optional setup */</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token function">pull</span><span class="token punctuation">(</span><span class="token parameter">controller</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    controller<span class="token punctuation">.</span><span class="token function">enqueue</span><span class="token punctuation">(</span><span class="token function">generateChunk</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token function">cancel</span><span class="token punctuation">(</span><span class="token parameter">reason</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token string">'Stream cancelled'</span><span class="token punctuation">,</span> reason<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Here, the browser calls <code>pull()</code> only when the consumer is ready for more data, creating natural backpressure.</p>
<h4 id="writablestream-signaling" tabindex="-1"><a class="header-anchor" href="#writablestream-signaling">WritableStream signaling</a></h4>
<p>When writing to a <code>WritableStream</code>, the <code>write()</code> promise only resolves when the consumer has processed the chunk. If the consumer is slow, <code>write()</code> automatically pauses the producer (the promise will stay pending):</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">const</span> writable <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">WritableStream</span><span class="token punctuation">(</span><span class="token punctuation">{</span>
  <span class="token function">write</span><span class="token punctuation">(</span><span class="token parameter">chunk</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">return</span> <span class="token function">processChunk</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// returns a promise</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<h3 id="where-browser-backpressure-can-break-down" tabindex="-1"><a class="header-anchor" href="#where-browser-backpressure-can-break-down">Where Browser Backpressure Can Break Down</a></h3>
<p>Even with these APIs, there are common pitfalls:</p>
<ul>
<li><strong>UI thread blocking</strong>: Long synchronous work can starve the main thread, causing latency even if streams are correctly used.</li>
<li><strong>Fire-and-forget async operations</strong>: Like in Node, launching many promises inside a <code>pull()</code> method can overwhelm the consumer.</li>
<li><strong>Ignoring transfer costs</strong>: Passing large objects between threads (e.g., with <code>postMessage</code>) can trigger copying overhead if you don't use <code>Transferables</code>.</li>
</ul>
<p>As we can see, backpressure in the browser works similarly to Node.js streams: <strong>the consumer drives the pace of the producer</strong>. Properly used, it prevents memory spikes and keeps your app responsive. Ignoring these mechanisms - by reading entire responses at once, launching unbounded promises, or blocking the UI - defeats backpressure, creating systems that can crash or become unresponsive under load.</p>
<p>It's still about signaling readiness, not just awaiting asynchronous operations. JavaScript provides the primitives in both Node and the browser, but <strong>developers must respect them</strong>.</p>
<h2 id="buffers%3A-the-double-edged-sword" tabindex="-1"><a class="header-anchor" href="#buffers%3A-the-double-edged-sword">Buffers: The Double-Edged Sword</a></h2>
<p>Buffers are everywhere in JavaScript streams. They act as <strong>shock absorbers</strong>, temporarily storing data when the producer is faster than the consumer. While buffers are essential for smooth streaming, <strong>they can also mask backpressure problems</strong> if misused.</p>
<h3 id="what-buffers-do" tabindex="-1"><a class="header-anchor" href="#what-buffers-do">What Buffers Do</a></h3>
<p>A buffer's main purpose is to <strong>decouple producer speed from consumer speed</strong>. By holding onto data temporarily, buffers allow small variations in processing time without immediately stalling the producer. In the example earlier:</p>
<pre class="language-js"><code class="language-js"><span class="token keyword">const</span> fs <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'fs'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> readable <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">createReadStream</span><span class="token punctuation">(</span><span class="token string">'largefile.txt'</span><span class="token punctuation">,</span> <span class="token punctuation">{</span> <span class="token literal-property property">highWaterMark</span><span class="token operator">:</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p><code>highWaterMark</code> sets the buffer size. The readable stream can accumulate up to 64 KB of data before signaling the producer to pause. This allows small variations in consumer speed without immediately blocking the producer.</p>
<p>Buffers exist in both Node streams and Web Streams, and their behavior is similar: they let the system manage short-term fluctuations in throughput.</p>
<h3 id="when-buffers-hide-problems" tabindex="-1"><a class="header-anchor" href="#when-buffers-hide-problems">When Buffers Hide Problems</a></h3>
<p>Problems arise when buffers are unbounded or ignored:</p>
<ul>
<li><strong>Memory growth</strong>: If the consumer can't keep up and the buffer grows beyond expectations, your app can exhaust memory.</li>
<li><strong>Latency spikes</strong>: Large buffers introduce additional delay before the consumer sees new data.</li>
<li><strong>Delayed failure</strong>: Buffers can postpone a crash, making the problem harder to detect until traffic spikes dramatically.</li>
</ul>
<p>Take this example:</p>
<pre class="language-js"><code class="language-js"><span class="token comment">// Reading entire file into memory</span>
<span class="token keyword">const</span> data <span class="token operator">=</span> <span class="token keyword">await</span> fs<span class="token punctuation">.</span>promises<span class="token punctuation">.</span><span class="token function">readFile</span><span class="token punctuation">(</span><span class="token string">'hugefile.txt'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">process</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// instantaneous, but memory-heavy</span>
</code></pre>
<p>Even though this &quot;works&quot; for small files, it completely ignores backpressure. The buffer (memory) absorbs all data at once, leaving no flow control.</p>
<h3 id="how-to-use-buffers-wisely" tabindex="-1"><a class="header-anchor" href="#how-to-use-buffers-wisely">How to Use Buffers Wisely</a></h3>
<p>Buffers are powerful when bounded and intentional:</p>
<ul>
<li>Set reasonable highWaterMark values.</li>
<li>Respect writable return values and <code>drain</code> events.</li>
<li>Use streaming APIs instead of reading everything at once.</li>
<li>Combine with bounded concurrency for async tasks to avoid hidden buildup.</li>
</ul>
<p>Buffers should <strong>support backpressure, not replace it</strong>. Think of them as a cushion: they smooth out short-term spikes, but the consumer must still be able to handle the flow long-term.</p>
<p>Buffers are not a cure-all. They are a tool to make backpressure effective, not a substitute for it. Understanding their limits ensures that your Node.js and browser applications remain responsive, memory-safe, and resilient under load.</p>
<h2 id="recognizing-backpressure-problems-in-real-apps" tabindex="-1"><a class="header-anchor" href="#recognizing-backpressure-problems-in-real-apps">Recognizing Backpressure Problems in Real Apps</a></h2>
<p>Backpressure problems usually don't announce themselves with clear errors: they creep in slowly, manifesting as memory growth, latency spikes, or unpredictable behavior. Perceiving these symptoms early is key to building robust asynchronous applications.</p>
<h3 id="common-symptoms" tabindex="-1"><a class="header-anchor" href="#common-symptoms">Common Symptoms</a></h3>
<h4 id="memory-growth-over-time" tabindex="-1"><a class="header-anchor" href="#memory-growth-over-time">Memory Growth Over Time</a></h4>
<ul>
<li>The app's memory usage steadily increases under load, even when requests are processed asynchronously.</li>
<li>Often caused by unbounded buffers or producers generating data faster than consumers can handle.</li>
</ul>
<h4 id="latency-collapse" tabindex="-1"><a class="header-anchor" href="#latency-collapse">Latency Collapse</a></h4>
<ul>
<li>Requests start taking longer as the system processes more data.</li>
<li>Queues form behind slow consumers, delaying new tasks.</li>
</ul>
<h4 id="crashes-or-out-of-memory-errors" tabindex="-1"><a class="header-anchor" href="#crashes-or-out-of-memory-errors">Crashes or Out-of-Memory Errors</a></h4>
<ul>
<li>Eventually, excessive buffering leads to process termination or browser tab crashes.</li>
</ul>
<h4 id="high-cpu-with-low-throughput" tabindex="-1"><a class="header-anchor" href="#high-cpu-with-low-throughput">High CPU with Low Throughput</a></h4>
<ul>
<li>A symptom of inefficient flow: the CPU is busy juggling many small tasks, but actual work completion lags behind.</li>
</ul>
<h3 id="diagnostic-questions" tabindex="-1"><a class="header-anchor" href="#diagnostic-questions">Diagnostic Questions</a></h3>
<p>When backpressure issues appear, ask:</p>
<ul>
<li>Where does data queue? Are producers creating more work than consumers can handle?</li>
<li>Does your code respect the backpressure signals provided by streams or async iterators?</li>
<li>Are you launching too many concurrent promises (e.g., with <code>Promise.all()</code> or unbounded async loops)?</li>
<li>Are buffers growing unbounded in Node streams, fetch requests, or Web Streams?</li>
</ul>
<h3 id="early-warning-tips" tabindex="-1"><a class="header-anchor" href="#early-warning-tips">Early Warning Tips</a></h3>
<ul>
<li>Monitor memory usage in development under realistic load.</li>
<li>Test streams with intentionally slow consumers to observe backpressure behavior.</li>
<li>Use small bounded buffers and gradually scale them up.</li>
</ul>
<p>Backpressure issues are often subtle but predictable. By watching for memory growth, latency spikes, and unbounded concurrency, you can identify potential problems before they hit production and design your streams and async flows to respect the natural pace of your consumers.</p>
<h2 id="designing-backpressure-friendly-javascript-code" tabindex="-1"><a class="header-anchor" href="#designing-backpressure-friendly-javascript-code">Designing Backpressure-Friendly JavaScript Code</a></h2>
<p>Understanding backpressure conceptually is important, but the real benefit comes from writing code that respects it. In JavaScript, both Node.js and the browser provide primitives for flow controlâ€”but it's up to the developer to use them correctly.</p>
<p>This section focuses on patterns and strategies for designing JavaScript applications that handle high-volume or fast data streams safely, without repeating low-level stream API details.</p>
<h3 id="think-in-terms-of-flow%2C-not-tasks" tabindex="-1"><a class="header-anchor" href="#think-in-terms-of-flow%2C-not-tasks">Think in Terms of Flow, Not Tasks</a></h3>
<p>Backpressure is about coordinating producer and consumer rates. Instead of thinking in terms of &quot;launch tasks as fast as possible&quot;, design your system around how much work can actually be handled at a time.</p>
<ul>
<li>Identify natural boundaries: buffers, streams, network requests, or event loops.</li>
<li>Avoid unbounded queues of work (e.g., infinite <code>Promise.all()</code> or uncontrolled event handlers).</li>
</ul>
<h3 id="use-pull-based-or-demand-driven-designs" tabindex="-1"><a class="header-anchor" href="#use-pull-based-or-demand-driven-designs">Use Pull-Based or Demand-Driven Designs</a></h3>
<ul>
<li><strong>Producer-driven</strong>: Traditional model where the producer pushes data. Requires careful monitoring of buffers and signals.</li>
<li><strong>Consumer-driven</strong>: Better pattern for JavaScript: consumers pull data when ready. This naturally enforces backpressure, especially with Web Streams or async iterators.</li>
</ul>
<p>The guiding principle: the <strong>consumer should control the pace</strong>.</p>
<h3 id="bound-concurrency" tabindex="-1"><a class="header-anchor" href="#bound-concurrency">Bound Concurrency</a></h3>
<p>Even when using <code>async/await</code>, unbounded parallelism is dangerous. Instead of letting every task run simultaneously:</p>
<ul>
<li>Use worker pools for CPU-heavy tasks.</li>
<li>Use limited async queues for I/O-heavy tasks.</li>
<li>Measure the &quot;sweet spot&quot; for concurrency empirically, considering memory, CPU, and network.</li>
</ul>
<p>This ensures your system scales without crashing, even if the producer is fast.</p>
<h3 id="monitor-and-react" tabindex="-1"><a class="header-anchor" href="#monitor-and-react">Monitor and React</a></h3>
<p>Design systems to observe flow in real time:</p>
<ul>
<li>Track buffer lengths, memory growth, and queue sizes.</li>
<li>Detect when consumers lag and temporarily slow producers if possible.</li>
<li>Introduce graceful degradation rather than letting memory explode or requests fail silently.</li>
</ul>
<h3 id="prefer-declarative-coordination" tabindex="-1"><a class="header-anchor" href="#prefer-declarative-coordination">Prefer Declarative Coordination</a></h3>
<p>Instead of manually juggling streams and buffers:</p>
<ul>
<li>Use high-level libraries that implement flow control primitives.</li>
<li>Prefer iterators, async generators, and pull-based streams to abstract away low-level buffering logic.</li>
<li>Focus on designing pipelines that express intentional flow control rather than ad-hoc buffering.</li>
</ul>
<p>Backpressure-friendly design is system thinking applied in JavaScript: coordinate producers and consumers, limit concurrency, and observe flow continuously. By applying these principles, your applications can handle large datasets, fast streams, or bursts of requests without depending on trial-and-error or unbounded buffers.</p>
<h2 id="conclusion%3A-respect-the-flow" tabindex="-1"><a class="header-anchor" href="#conclusion%3A-respect-the-flow">Conclusion: Respect the Flow</a></h2>
<p>Backpressure isn't an optional detail in asynchronous JavaScript, it's a fundamental property of any system where producers can generate data faster than consumers can handle. From Node.js streams to <code>fetch</code> and Web Streams in the browser, JavaScript provides primitives that allow consumers to signal readiness and prevent runaway memory growth or latency spikes.</p>
<p>The key lessons are:</p>
<ul>
<li>Identify producers and consumers. Understand where data is generated and where it's processed.</li>
<li>Respect the signals. Streams provide built-in backpressure mechanisms (<code>write()</code> return values, <code>drain</code> events, <code>pull()</code> in Web Streams), and async iterators can enforce flow when used correctly.</li>
<li>Bound concurrency. Avoid unbounded <code>Promise.all()</code> or fire-and-forget loops. Use worker pools, limited queues, or libraries for controlled parallelism.</li>
<li>Use buffers wisely. Buffers smooth temporary spikes but are not a substitute for proper flow control. Always keep them bounded.</li>
<li>Monitor and diagnose: watch memory, queue lengths, and latency to catch hidden backpressure problems before they impact production.</li>
</ul>
<p>By designing systems that respect the natural pace of their consumers, JavaScript developers can handle large datasets, high-throughput streams, or bursty network traffic safely and efficiently. Backpressure is not a limitation, it's a feature that enables robust, scalable, and maintainable asynchronous code.</p>

  </div>
</article>

  </div>
  </main>

  <!-- Footer -->
  <footer class="border-t border-gray-100 bg-gray-50 dark:bg-gray-900 text-gray-900 dark:text-gray-100 mt-20 transition-colors">
    <div class="max-w-4xl mx-auto px-6 py-12">
      <div class="text-center text-sm text-gray-600 dark:text-gray-300">
        <p>&copy; <span id="footer-year"></span> Gabor Koos</p>
      </div>
    </div>
  </footer>
  <!-- Theme Switcher Script -->
  <script>
    // Footer year
    document.getElementById('footer-year').textContent = new Date().getFullYear();
    // Theme switcher logic
    const root = document.documentElement;
    const themeToggle = document.getElementById('theme-toggle');
    const lightIcon = document.getElementById('theme-toggle-light');
    const darkIcon = document.getElementById('theme-toggle-dark');
    function setTheme(mode) {
      if (mode === 'dark') {
        root.classList.add('dark');
        localStorage.setItem('theme', 'dark');
        darkIcon.style.display = 'none';
        lightIcon.style.display = '';
      } else {
        root.classList.remove('dark');
        localStorage.setItem('theme', 'light');
        darkIcon.style.display = '';
        lightIcon.style.display = 'none';
      }
    }
    // Initial theme
    const userTheme = localStorage.getItem('theme');
    const systemDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
    if (userTheme === 'dark' || (!userTheme && systemDark)) {
      setTheme('dark');
    } else {
      setTheme('light');
    }
    // Button is always visible; only icons are toggled
    themeToggle.addEventListener('click', () => {
    if (root.classList.contains('dark')) {
      setTheme('light');
    } else {
      setTheme('dark');
    }
    });
  </script>
</body>

<script>
document.addEventListener('DOMContentLoaded', function () {
  document.querySelectorAll('pre code').forEach(function (codeBlock) {
    var pre = codeBlock.parentNode;
    pre.style.position = 'relative';
    pre.style.overflow = 'auto';

    var button = document.createElement('button');
    button.className = 'copy-btn';
    button.type = 'button';
    button.innerHTML = '<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="#333" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg>';
    button.style = 'position:absolute;top:0.2em;right:0.2em;padding:0.05em 0.05em;width:1.2em;height:1.2em;display:flex;align-items:center;justify-content:center;background:#eee;border-radius:0.2em;border:none;cursor:pointer;z-index:1;opacity:0.7;box-shadow:0 2px 8px rgba(0,0,0,0.08);transition:opacity 0.2s;pointer-events:auto;';
    button.onmouseenter = function() { button.style.opacity = '1'; };
    button.onmouseleave = function() { button.style.opacity = '0.7'; };
    pre.appendChild(button);
    button.addEventListener('click', function () {
      navigator.clipboard.writeText(codeBlock.innerText);
      var original = button.innerHTML;
      button.innerHTML = '<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="#16a34a" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="20 6 9 17 4 12"/></svg>';
      setTimeout(function () {
        button.innerHTML = original;
      }, 1200);
    });
  });
});
</script>

</body>
</html>
